{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "lHbVlxwD-V9P",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hp72dD0i_PF-",
    "outputId": "0f13acdf-1ed6-4fca-c430-87052770ff2d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "data_matrix = pd.read_csv('/Users/jackmayr/PycharmProjects/Notebooks/nasa.csv')\n",
    "data_matrix\n",
    "data_matrix = data_matrix.drop(columns = ['Miss Dist.(kilometers)', 'Orbit ID', 'Neo Reference ID', 'Name', 'Orbit Determination Date', 'Close Approach Date',  'Epoch Date Close Approach' ,'Est Dia in KM(min)', 'Est Dia in KM(max)', 'Est Dia in M(min)', 'Est Dia in M(max)', 'Est Dia in Miles(min)', 'Est Dia in Miles(max)', 'Orbiting Body', 'Epoch Osculation','Equinox'])\n",
    "data_matrix.loc[data_matrix['Hazardous']== True, 'Hazardous'] = 1 \n",
    "data_matrix.loc[data_matrix['Hazardous']== False, 'Hazardous'] = 0 \n",
    "data_matrix\n",
    "print(len(data_matrix.columns))"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float32)"
   ],
   "metadata": {
    "id": "9Ao0rQAWMDSB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_matrix = clean_dataset(data_matrix)\n",
    "data_matrix\n",
    "print(len(data_matrix[data_matrix['Hazardous'] >0]))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMHANCgeMD5c",
    "outputId": "6359b2ec-4b16-4841-8f90-71ac7ab8dc6d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgmT7lcL_fql",
    "outputId": "c270ea91-81cf-4423-d572-f1b6ff2e6f78",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\n",
    "X = data_matrix.drop(columns = ['Hazardous'])\n",
    "y = data_matrix['Hazardous']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(18, input_shape = (23,)),\n",
    "                                   tf.keras.layers.Dense(32),\n",
    "                                   tf.keras.layers.Dense(64),\n",
    "                                   tf.keras.layers.Dense(64),\n",
    "                                   tf.keras.layers.Dense(32),\n",
    "                                   tf.keras.layers.Dense(16),\n",
    "                                    \n",
    "                                   tf.keras.layers.Dense(1, activation = 'relu')])\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 100, batch_size = 32, verbose = 1)\n",
    "print(history.epoch, history.history['accuracy'][-1])"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2.2384 - accuracy: 0.8015\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.8387 - accuracy: 0.8418\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2.7153 - accuracy: 0.7711\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.9251 - accuracy: 0.8346\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.8354 - accuracy: 0.8448\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.5113 - accuracy: 0.8650\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.3195 - accuracy: 0.8786\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.7813 - accuracy: 0.9018\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.9130\n",
      "Epoch 10/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.9053\n",
      "Epoch 11/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.5985 - accuracy: 0.9122\n",
      "Epoch 12/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.9205\n",
      "Epoch 13/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.6152 - accuracy: 0.9133\n",
      "Epoch 14/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.9384\n",
      "Epoch 15/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.9368\n",
      "Epoch 16/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.9483\n",
      "Epoch 17/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1433 - accuracy: 0.9496\n",
      "Epoch 18/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.9360\n",
      "Epoch 19/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1187 - accuracy: 0.9517\n",
      "Epoch 20/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9523\n",
      "Epoch 21/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9517\n",
      "Epoch 22/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9523\n",
      "Epoch 23/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.3979 - accuracy: 0.9210\n",
      "Epoch 24/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.9245\n",
      "Epoch 25/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9325\n",
      "Epoch 26/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.6776 - accuracy: 0.8949\n",
      "Epoch 27/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9250\n",
      "Epoch 28/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.9467\n",
      "Epoch 29/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.9477\n",
      "Epoch 30/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9493\n",
      "Epoch 31/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.9512\n",
      "Epoch 32/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9496\n",
      "Epoch 33/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9528\n",
      "Epoch 34/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9517\n",
      "Epoch 35/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9509\n",
      "Epoch 36/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9528\n",
      "Epoch 37/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.9536\n",
      "Epoch 38/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.9437\n",
      "Epoch 39/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.9184\n",
      "Epoch 40/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9464\n",
      "Epoch 41/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.9240\n",
      "Epoch 42/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9451\n",
      "Epoch 43/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9512\n",
      "Epoch 44/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9517\n",
      "Epoch 45/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9416\n",
      "Epoch 46/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1736 - accuracy: 0.9365\n",
      "Epoch 47/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.1156 - accuracy: 0.9533\n",
      "Epoch 48/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.9523\n",
      "Epoch 49/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.9389\n",
      "Epoch 50/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9496\n",
      "Epoch 51/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9536\n",
      "Epoch 52/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9483\n",
      "Epoch 53/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9448\n",
      "Epoch 54/100\n",
      "118/118 [==============================] - 0s 3ms/step - loss: 0.2223 - accuracy: 0.9290\n",
      "Epoch 55/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9517\n",
      "Epoch 56/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1722 - accuracy: 0.9437\n",
      "Epoch 57/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9461\n",
      "Epoch 58/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1031 - accuracy: 0.9528\n",
      "Epoch 59/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9536\n",
      "Epoch 60/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9488\n",
      "Epoch 61/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1227 - accuracy: 0.9475\n",
      "Epoch 62/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9531\n",
      "Epoch 63/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9525\n",
      "Epoch 64/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9485\n",
      "Epoch 65/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.9248\n",
      "Epoch 66/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.9453\n",
      "Epoch 67/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9477\n",
      "Epoch 68/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.9496\n",
      "Epoch 69/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1639 - accuracy: 0.9411\n",
      "Epoch 70/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9493\n",
      "Epoch 71/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.9138\n",
      "Epoch 72/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.7888 - accuracy: 0.8829\n",
      "Epoch 73/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9445\n",
      "Epoch 74/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9525\n",
      "Epoch 75/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9448\n",
      "Epoch 76/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9496\n",
      "Epoch 77/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1676 - accuracy: 0.9464\n",
      "Epoch 78/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9493\n",
      "Epoch 79/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.9456\n",
      "Epoch 80/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 0.2617 - accuracy: 0.9258\n",
      "Epoch 81/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.0053 - accuracy: 0.8944\n",
      "Epoch 82/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 6.7112 - accuracy: 0.5356\n",
      "Epoch 83/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 3.6271 - accuracy: 0.7447\n",
      "Epoch 84/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 4.1184 - accuracy: 0.7261\n",
      "Epoch 85/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 4.0811 - accuracy: 0.7279\n",
      "Epoch 86/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 3.8089 - accuracy: 0.7453\n",
      "Epoch 87/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 3.2612 - accuracy: 0.7815\n",
      "Epoch 88/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 2.2515 - accuracy: 0.8448\n",
      "Epoch 89/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.6458 - accuracy: 0.8848\n",
      "Epoch 90/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.3504 - accuracy: 0.9026\n",
      "Epoch 91/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.2179 - accuracy: 0.9106\n",
      "Epoch 92/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 1.0612 - accuracy: 0.9157\n",
      "Epoch 93/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 0.9472 - accuracy: 0.9197\n",
      "Epoch 94/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 2.8470 - accuracy: 0.8037\n",
      "Epoch 95/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 4.2564 - accuracy: 0.7186\n",
      "Epoch 96/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 4.2258 - accuracy: 0.7210\n",
      "Epoch 97/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 3.8227 - accuracy: 0.7469\n",
      "Epoch 98/100\n",
      "118/118 [==============================] - 0s 1ms/step - loss: 3.3996 - accuracy: 0.7751\n",
      "Epoch 99/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 3.2625 - accuracy: 0.7826\n",
      "Epoch 100/100\n",
      "118/118 [==============================] - 0s 2ms/step - loss: 3.1123 - accuracy: 0.7927\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] 0.7927447557449341\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zaRO_ejZLgTB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "79cb7ed5-315d-41e1-aa35-a8f0db21659a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(model.evaluate(X_test, y_test))\n",
    "#print(model.predict(X_test))\n",
    "print(tf.math.confusion_matrix(y_test, model.predict(X_test)))"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "30/30 [==============================] - 0s 3ms/step - loss: 2.3187 - accuracy: 0.8497\n",
      "[2.3186755180358887, 0.8496801853179932]\n",
      "30/30 [==============================] - 0s 3ms/step\n",
      "tf.Tensor(\n",
      "[[797   0]\n",
      " [141   0]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ]
  }
 ]
}